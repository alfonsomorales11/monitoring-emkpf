apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-overrides
  namespace: kube-system
data:
  filter-exclude-journal-debug.conf: |-
    <filter journal>
      @type grep
      <exclude>
        key PRIORITY
        pattern ^7$
      </exclude>
    </filter>

  filter-k8s-meta.conf: |-
    <filter kubernetes.**>
      type kubernetes_metadata
      kubernetes_url "#{ENV['K8S_HOST_URL']}"
      cache_size "#{ENV['K8S_METADATA_CACHE_SIZE'] || '1000'}"
      watch "#{ENV['K8S_METADATA_WATCH'] || 'false'}"
      bearer_token_file /var/run/secrets/kubernetes.io/serviceaccount/token
      ca_file /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      include_namespace_metadata true
      use_journal "#{ENV['USE_JOURNAL'] || 'false'}"
      container_name_to_kubernetes_regexp '^(?<name_prefix>[^_]+)_(?<container_name>[^\._]+)(\.(?<container_hash>[^_]+))?_(?<pod_name>[^_]+)_(?<namespace>[^_]+)_[^_]+_[^_]+$'
      merge_json_log false
    </filter>

  filter-k8s-record-transform.conf: |-

  filter-kibana-transform.conf: |-
    <filter **kibana**>
      @type record_transformer
      enable_ruby
      <record>
        log ${record['err'] || record['msg'] || record['MESSAGE'] || record['log']}
      </record>
      remove_keys req,res,msg,name,level,v,pid,err
    </filter>

  filter-post-genid.conf: |-
    # generate ids at source mitigate creating duplicate records
    # requires fluent-plugin-elasticsearch
    <filter **>
      @type elasticsearch_genid
      hash_id_key viaq_msg_id
    </filter>

  filter-pre-force-utf8.conf: |-
    <filter **>
      @type record_modifier
      char_encoding utf-8
    </filter>

  filter-retag-journal.conf: |-
    # journal entries from k8s containers look like this:
    # The stream identification is encoded into the PRIORITY field as an
    # integer: 6, or github.com/coreos/go-systemd/journal.Info, marks stdout,
    # while 3, or github.com/coreos/go-systemd/journal.Err, marks stderr.
    # PRIORITY=6
    # CONTAINER_ID=b6cbb6e73c0a
    # CONTAINER_ID_FULL=b6cbb6e73c0ad63ab820e4baa97cdc77cec729930e38a714826764ac0491341a
    # CONTAINER_NAME=k8s_registry.a49f5318_docker-registry-1-hhoj0_default_ae3a9bdc-1f66-11e6-80a2-fa163e2fff3a_799e4035
    # MESSAGE=172.17.0.1 - - [21/May/2016:16:52:05 +0000] "GET /healthz HTTP/1.1" 200 0 "" "Go-http-client/1.1"
    # or
    # MESSAGE=time="2016-05-21T15:14:17.216966675Z" level=info msg="version=v2.1.0+unknown"
    # docker inspect:
    # "io.kubernetes.container.hash": "a49f5318",
    # "io.kubernetes.container.name": "registry",
    # "io.kubernetes.pod.name": "docker-registry-1-hhoj0",
    # "io.kubernetes.pod.namespace": "default",
    # "io.kubernetes.pod.terminationGracePeriod": "30",
    # "io.kubernetes.pod.uid": "ae3a9bdc-1f66-11e6-80a2-fa163e2fff3a",
    # docker ps:
    # da531d7cea12 172.30.38.242:5000/logging/logging-elasticsearch@sha256:4888a2a3f875555a46d233f9856964a8eaac716259599db0062051ba5647187e   "sh /opt/app-root/src"   About an hour ago   Up About an hour
    # k8s_elasticsearch.8d3af8fd_logging-es-ops-gkfv06wi-1-7y682_logging_9612f891-1f68-11e6-80a2-fa163e2fff3a_d1cc32e1
    # oc get pods -o yaml:
    #      kubernetes.io/created-by: |
    # {"name":"logging-es-ops-gkfv06wi-1","uid":"92d90581-1f68-11e6-80a2-fa163e2fff3a","apiVersion":"v1","resourceVersion":"829"}}
    # openshift.io/deployment-config.name: logging-es-ops-gkfv06wi
    # openshift.io/deployment.name: logging-es-ops-gkfv06wi-1
    # uid: 9612f891-1f68-11e6-80a2-fa163e2fff3a
    # image: 172.30.38.242:5000/logging/logging-elasticsearch@sha256:4888a2a3f875555a46d233f9856964a8eaac716259599db0062051ba5647187e
    # containerStatuses:
    #  - containerID: docker://da531d7cea12bf714f90c26d0fb9f275b02321d1bccd10013f087be33f4e6e5e
    #    image: 172.30.38.242:5000/logging/logging-elasticsearch@sha256:4888a2a3f875555a46d233f9856964a8eaac716259599db0062051ba5647187e
    #    imageID: docker://sha256:d5a02bf63b1f3e0d1aa06bf28928e181f67ab2c80b2a1d1fd1ba310f11c12955
    # another example:
    # CONTAINER_NAME=k8s_bob.94e110c7_bob-iq0d4_default_2d67916a-1eac-11e6-94ba-001c42e13e5d_8b4b7e3d
    # From this, we can extract:
    #    container name in pod: bob
    #    pod name: bob-iq0d4
    #    namespace: default
    #    pod uid: 2d67916a-1eac-11e6-94ba-001c42e13e5d

    # in addition, there are a few other differences about /var/log/messages and journal messages
    # * the default rsyslog.conf on el7 will only log messages to /var/log/messages at INFO level
    #   or higher
    # * the default rsyslog.d includes 21-cloudinit.conf which redirects all cloud-init messages
    #   to /var/log/cloud-init.log
    #   When using the journal, we keep the cloud-init messages and store
    #   them in elasticsearch.  But we filter out DEBUG messages.
    #   We should revisit this at a later date, when we have a good grasp of the storage
    #   requirements, so we can turn on this firehose.

    @include filter-exclude-journal-debug.conf

    <match journal>
      @type rewrite_tag_filter
      # skip to @INGRESS label section
      @label @INGRESS
      # see if this is a kibana container for special log handling
      # looks like this:
      # k8s_kibana.a67f366_logging-kibana-1-d90e3_logging_26c51a61-2835-11e6-ad29-fa163e4944d5_f0db49a2
      # we filter these logs through the kibana_transform.conf filter
      rewriterule1 CONTAINER_NAME ^k8s_kibana\. kubernetes.journal.container.kibana
      # mark for processing as k8s logs but stored as system logs
      rewriterule2 CONTAINER_NAME ^k8s_[^_]+_[^_]+_default_ kubernetes.journal.container._default_
      # mark for processing as k8s logs but stored as system logs
      rewriterule3 CONTAINER_NAME ^k8s_[^_]+_[^_]+_openshift-infra_ kubernetes.journal.container._openshift-infra_
      # mark for processing as k8s logs but stored as system logs
      rewriterule4 CONTAINER_NAME ^k8s_[^_]+_[^_]+_openshift_ kubernetes.journal.container._openshift_
      # mark fluentd container logs
      rewriterule5 CONTAINER_NAME ^k8s_.*fluentd kubernetes.journal.container.fluentd
      # this is a kubernetes container
      rewriterule6 CONTAINER_NAME ^k8s_ kubernetes.journal.container
      # mark non-kubernetes openshift-infra container logs as system logs
      rewriterule7 CONTAINER_NAME _openshift-infra_ journal.container._openshift-infra_
      # mark non-kubernetes openshift container logs as system logs
      rewriterule8 CONTAINER_NAME _openshift_ journal.container._openshift_
      # not kubernetes - assume a system log
      rewriterule9 _TRANSPORT .+ journal.system
    </match>

  filter-syslog-record-transform.conf: |-

  filter-viaq-data-model.conf: |-
    <filter **>
      @type viaq_data_model
      default_keep_fields CEE,docker,file,geoip,hostname,kubernetes,level,message,offset,pid,pipeline_metadata,rsyslog,service,systemd,tags,time,ovirt,collectd,tlog,aushape,namespace_name,namespace_uuid
      extra_keep_fields "#{ENV['CDM_EXTRA_KEEP_FIELDS'] || ''}"
      keep_empty_fields "#{ENV['CDM_KEEP_EMPTY_FIELDS'] || 'message'}"
      use_undefined "#{ENV['CDM_USE_UNDEFINED'] || false}"
      undefined_name "#{ENV['CDM_UNDEFINED_NAME'] || 'undefined'}"
      rename_time "#{ENV['CDM_RENAME_TIME'] || true}"
      rename_time_if_missing "#{ENV['CDM_RENAME_TIME_IF_MISSING'] || false}"
      src_time_name "#{ENV['CDM_SRC_TIME_NAME'] || 'time'}"
      dest_time_name "#{ENV['CDM_DEST_TIME_NAME'] || '@timestamp'}"
      pipeline_type "#{ENV['PIPELINE_TYPE'] || 'collector'}"
      <formatter>
        enabled false
        tag "audit.log**"
        type sys_var_log
      </formatter>
      <formatter>
        # already processed - just do index_name
        enabled false
        tag "**mux"
        # type doesn't matter because it will be skipped
        type sys_var_log
      </formatter>
      <formatter>
        tag "system.var.log**"
        type sys_var_log
        remove_keys host,pid,ident
      </formatter>
      <formatter>
        tag "journal.system**"
        type sys_journal
        remove_keys log,stream,MESSAGE,_SOURCE_REALTIME_TIMESTAMP,__REALTIME_TIMESTAMP,CONTAINER_ID,CONTAINER_ID_FULL,CONTAINER_NAME,PRIORITY,_BOOT_ID,_CAP_EFFECTIVE,_CMDLINE,_COMM,_EXE,_GID,_HOSTNAME,_MACHINE_ID,_PID,_SELINUX_CONTEXT,_SYSTEMD_CGROUP,_SYSTEMD_SLICE,_SYSTEMD_UNIT,_TRANSPORT,_UID,_AUDIT_LOGINUID,_AUDIT_SESSION,_SYSTEMD_OWNER_UID,_SYSTEMD_SESSION,_SYSTEMD_USER_UNIT,CODE_FILE,CODE_FUNCTION,CODE_LINE,ERRNO,MESSAGE_ID,RESULT,UNIT,_KERNEL_DEVICE,_KERNEL_SUBSYSTEM,_UDEV_SYSNAME,_UDEV_DEVNODE,_UDEV_DEVLINK,SYSLOG_FACILITY,SYSLOG_IDENTIFIER,SYSLOG_PID
      </formatter>
      <formatter>
        tag "kubernetes.journal.container**"
        type k8s_journal
        remove_keys "#{ENV['K8S_FILTER_REMOVE_KEYS'] || 'log,stream,MESSAGE,_SOURCE_REALTIME_TIMESTAMP,__REALTIME_TIMESTAMP,CONTAINER_ID,CONTAINER_ID_FULL,CONTAINER_NAME,PRIORITY,_BOOT_ID,_CAP_EFFECTIVE,_CMDLINE,_COMM,_EXE,_GID,_HOSTNAME,_MACHINE_ID,_PID,_SELINUX_CONTEXT,_SYSTEMD_CGROUP,_SYSTEMD_SLICE,_SYSTEMD_UNIT,_TRANSPORT,_UID,_AUDIT_LOGINUID,_AUDIT_SESSION,_SYSTEMD_OWNER_UID,_SYSTEMD_SESSION,_SYSTEMD_USER_UNIT,CODE_FILE,CODE_FUNCTION,CODE_LINE,ERRNO,MESSAGE_ID,RESULT,UNIT,_KERNEL_DEVICE,_KERNEL_SUBSYSTEM,_UDEV_SYSNAME,_UDEV_DEVNODE,_UDEV_DEVLINK,SYSLOG_FACILITY,SYSLOG_IDENTIFIER,SYSLOG_PID'}"
      </formatter>
      <formatter>
        tag "kubernetes.var.log.containers**"
        type k8s_json_file
        remove_keys log,stream,CONTAINER_ID_FULL,CONTAINER_NAME
      </formatter>
      <elasticsearch_index_name>
        enabled "#{ENV['ENABLE_ES_INDEX_NAME'] || 'true'}"
        tag "journal.system** system.var.log** **_default_** **_openshift_** **_openshift-infra_** audit.log**"
        name_type operations_full
      </elasticsearch_index_name>
      <elasticsearch_index_name>
        enabled "#{ENV['ENABLE_ES_INDEX_NAME'] || 'true'}"
        tag "**"
        name_type project_full
      </elasticsearch_index_name>
    </filter>

  input-pre-systemd.conf: |-
    <source>
      @type systemd
      @label @INGRESS
      path "#{ENV['JOURNAL_SOURCE'] || '/run/log/journal'}"
      pos_file "#{ENV['JOURNAL_POS_FILE'] || '/var/log/journal.pos'}"
      filters "#{ENV['JOURNAL_FILTERS_JSON'] || '[]'}"
      tag journal
      read_from_head "#{ENV['JOURNAL_READ_FROM_HEAD'] || 'false'}"
    </source>

  output-applications.conf: |-
    <match retry_es>
      @type copy
      @include output-es-retry.conf
    </match>
    <match **>
      @type copy
      @include output-es-config.conf
      @include ../dynamic/output-remote-syslog.conf
      @include ../user/output-extra-*.conf
      @include ../user/secure-forward.conf
    </match>

  output-es-config.conf: |-
        <store>
          @type elasticsearch
          host "#{ENV['ES_HOST']}"
          port "#{ENV['ES_PORT']}"
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme

          client_key "#{ENV['ES_CLIENT_KEY']}"
          client_cert "#{ENV['ES_CLIENT_CERT']}"
          ca_file "#{ENV['ES_CA']}"

          type_name com.redhat.viaq.common
          retry_tag "retry_es"

          # there is currently a bug in the es plugin + excon - cannot
          # recreate/reload connections
          reload_connections false
          reload_on_failure false
          flush_interval "#{ENV['ES_FLUSH_INTERVAL'] || '1s'}"
          max_retry_wait "#{ENV['ES_RETRY_WAIT'] || '300'}"
          disable_retry_limit true
          buffer_type file
          buffer_path '/var/lib/fluentd/buffer-output-es-config'
          buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
          buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
          buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"

          write_operation 'create'

          # 2 ^ 31
          request_timeout 2147483648
        </store>

  output-es-ops-config.conf: |-
        <store>
          @type elasticsearch
          host "#{ENV['OPS_HOST']}"
          port "#{ENV['OPS_PORT']}"
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme

          client_key "#{ENV['OPS_CLIENT_KEY']}"
          client_cert "#{ENV['OPS_CLIENT_CERT']}"
          ca_file "#{ENV['OPS_CA']}"

          type_name com.redhat.viaq.common
          retry_tag "retry_es_ops"

          # there is currently a bug in the es plugin + excon - cannot
          # recreate/reload connections
          reload_connections false
          reload_on_failure false
          flush_interval "#{ENV['OPS_FLUSH_INTERVAL'] || ENV['ES_FLUSH_INTERVAL'] || '1s'}"
          max_retry_wait "#{ENV['OPS_RETRY_WAIT'] || ENV['ES_RETRY_WAIT'] || '300'}"
          disable_retry_limit true
          buffer_type file
          buffer_path '/var/lib/fluentd/buffer-output-es-ops-config'
          buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
          buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
          buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"

          write_operation 'create'

          # 2 ^ 31
          request_timeout 2147483648
        </store>

  output-es-ops-retry.conf: |-
        <store>
          @type elasticsearch
          host "#{ENV['OPS_HOST']}"
          port "#{ENV['OPS_PORT']}"
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme

          client_key "#{ENV['OPS_CLIENT_KEY']}"
          client_cert "#{ENV['OPS_CLIENT_CERT']}"
          ca_file "#{ENV['OPS_CA']}"

          type_name com.redhat.viaq.common

          # there is currently a bug in the es plugin + excon - cannot
          # recreate/reload connections
          reload_connections false
          reload_on_failure false
          flush_interval "#{ENV['OPS_FLUSH_INTERVAL'] || ENV['ES_FLUSH_INTERVAL'] || '1s'}"
          max_retry_wait "#{ENV['OPS_RETRY_WAIT'] || ENV['ES_RETRY_WAIT'] || '300'}"
          disable_retry_limit true
          buffer_type file
          buffer_path '/var/lib/fluentd/es-ops-retry'
          buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
          buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
          buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"

          write_operation 'create'

          # 2 ^ 31
          request_timeout 2147483648
        </store>


  output-es-retry.conf: |-
        <store>
          @type elasticsearch
          host "#{ENV['ES_HOST']}"
          port "#{ENV['ES_PORT']}"
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user fluentd
          password changeme

          client_key "#{ENV['ES_CLIENT_KEY']}"
          client_cert "#{ENV['ES_CLIENT_CERT']}"
          ca_file "#{ENV['ES_CA']}"

          type_name com.redhat.viaq.common

          # there is currently a bug in the es plugin + excon - cannot
          # recreate/reload connections
          reload_connections false
          reload_on_failure false
          flush_interval "#{ENV['ES_FLUSH_INTERVAL'] || '1s'}"
          max_retry_wait "#{ENV['ES_RETRY_WAIT'] || '300'}"
          disable_retry_limit true
          buffer_type file
          buffer_path '/var/lib/fluentd/es-retry'
          buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
          buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
          buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"

          write_operation 'create'

          # 2 ^ 31
          request_timeout 2147483648
        </store>


  output-operations.conf: |-
    <match retry_es_ops>
      @type copy
      @include output-es-ops-retry.conf
    </match>
    <match output_ops_tag journal.system** system.var.log** **_default_** **_openshift_** **_openshift-infra_** mux.ops audit.log**>
      @type copy
      @include ../dynamic/output-es-ops-config.conf
      @include ../user/output-ops-extra-*.conf
      @include ../user/secure-forward.conf
    </match>

  system.conf: |-
    <system>
      log_level warn
    </system>

  